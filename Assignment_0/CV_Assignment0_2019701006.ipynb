{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 : Video to Image and vice-versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Capture frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Capture_Frames(path,output_dir,frameRate):\n",
    "    \n",
    "    # Path to video file caputers into object \n",
    "    vidObj = cv.VideoCapture(path)\n",
    "    \n",
    "    # Used as counter variable \n",
    "    count = 0\n",
    "  \n",
    "    # checks whether frames were extracted \n",
    "    success = 1\n",
    "    sec = 1\n",
    "    while success: \n",
    "          \n",
    "        vidObj.set(cv.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        \n",
    "        # vidObj object calls read function extract frames\n",
    "        success,image = vidObj.read()\n",
    "        if not success:\n",
    "            print(\"Can't receive frame. Exiting ...\")\n",
    "            break\n",
    "    \n",
    "        # Saves the frames with frame-count \n",
    "        # save frame as JPG file\n",
    "        cv.imwrite(os.path.join(output_dir, \"image_\"+str(count)+\".jpg\"), image)\n",
    "        \n",
    "        count+=1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame. Exiting ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "  \n",
    "    # Calling the function \n",
    "    path = \"input_data\\\\question1_1\\\\video1.mp4\"\n",
    "    output_dir = \"output_data\\\\video_to_frame\"\n",
    "    Capture_Frames(path,output_dir,frameRate=1) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Converting frames to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Frames_to_Video(input_dir,output_dir,fps):\n",
    "    img_array = []\n",
    "    \n",
    "    # Taking each image and forming array of images\n",
    "    for count in range(len(os.listdir(path))):\n",
    "        filename = path+'/image_'+str(count)+'.jpg'\n",
    "        img = cv.imread(filename)\n",
    "        height, width, layers = img.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(img)\n",
    " \n",
    "    # Defining the path and filename to save with fps and size(w*h)\n",
    "    vidoutObj = cv.VideoWriter(os.path.join(output_dir,'project.avi'),cv.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    " \n",
    "    # each image in image_array is written to videowriter object\n",
    "    for i in range(len(img_array)):\n",
    "        vidoutObj.write(img_array[i])\n",
    "    vidoutObj.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "  \n",
    "    # Calling the function \n",
    "    path = \"input_data\\\\question1_2\"\n",
    "    output_dir = \"output_data\\\\frame_to_video\"\n",
    "    Frames_to_Video(path,output_dir,fps=30) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 : Capturing Images from webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cam_Capture_Frames(output_dir,frameRate):\n",
    "    capture = cv.VideoCapture(0)\n",
    "\n",
    "    if not capture.isOpened():\n",
    "        print(\"Cannot open camera\")\n",
    "        exit()\n",
    "    count = 0\n",
    "    success = True\n",
    "    print('Press q to exit')\n",
    "    sec = 1\n",
    "    while success:\n",
    "        \n",
    "        capture.set(cv.CAP_PROP_POS_MSEC,sec*1000)\n",
    "        # Capture frame-by-frame\n",
    "        success, frame = capture.read()\n",
    "        # if frame is read correctly ret is True\n",
    "        if not success:\n",
    "            print(\"Can't receive frame. Exiting ...\")\n",
    "            break\n",
    "        \n",
    "        # Display the resulting frame\n",
    "        cv.imwrite(os.path.join(output_dir, \"image_\"+str(count)+\".jpg\"), frame)\n",
    "        cv.imshow('Frame', frame)\n",
    "        if cv.waitKey(1) == ord('q'):\n",
    "            break\n",
    "        count+=1\n",
    "        sec = sec + frameRate\n",
    "        sec = round(sec, 2)\n",
    "    # When everything done, release the capture\n",
    "    capture.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press q to exit\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "  \n",
    "    # Calling the function \n",
    "    output_dir = \"output_data\\\\frame_from_cam\"\n",
    "    Cam_Capture_Frames(output_dir,frameRate=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 : Chroma Keying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_keying(bgpath,fgpath,output_dir):\n",
    "    img_array = []\n",
    "    # Reading two videofile fg and bg\n",
    "    bg = cv.VideoCapture(bgpath)\n",
    "    fg = cv.VideoCapture(fgpath)\n",
    "\n",
    "    success,bg_frame = bg.read()\n",
    "    ret,fg_frame = fg.read()\n",
    "\n",
    "    count = 0\n",
    "    success = True\n",
    "    \n",
    "    print('Press q to exit')\n",
    "    while success:\n",
    "        success,bg_frame = bg.read()\n",
    "        ret,fg_frame = fg.read()\n",
    "        \n",
    "        if not success or not ret:\n",
    "            print(\"Can't receive frame. Exiting ...\")\n",
    "            break\n",
    "            \n",
    "        bg_frame = cv.resize(bg_frame,(640,360))\n",
    "        fg_frame = cv.resize(fg_frame,(640,360))\n",
    "        \n",
    "        # converting bgr to hsv color space\n",
    "        hsv = cv.cvtColor(bg_frame,cv.COLOR_BGR2HSV)\n",
    "        \n",
    "        # defining green color range and creating a mask\n",
    "        lower_green = np.array([50,150,10])\n",
    "        upper_green = np.array([70,255,255])\n",
    "        mask1 = cv.inRange(hsv, lower_green, upper_green)\n",
    "        \n",
    "        # inverting the mask to remove detected green color\n",
    "        mask2 = cv.bitwise_not(mask1)\n",
    "        \n",
    "        # bitwise anding bg_frame with inverted mask to remove green color from frame\n",
    "        res1 = cv.bitwise_and(bg_frame,bg_frame,mask=mask2)\n",
    "        \n",
    "        # bitwise anding fg_frame with mask of green color detected to replace green color pixels with fg_frame pixels \n",
    "        res2 = cv.bitwise_and(fg_frame, fg_frame, mask = mask1)\n",
    "        \n",
    "        # adding both bg and fg frames together\n",
    "        output = cv.addWeighted(res1,1,res2,1,0)\n",
    "\n",
    "        cv.imshow('frame',output)\n",
    "        \n",
    "        height, width, layers = output.shape\n",
    "        size = (width,height)\n",
    "        img_array.append(output)\n",
    "        \n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    vidoutObj = cv.VideoWriter(os.path.join(output_dir,'chroma_keying.avi'),cv.VideoWriter_fourcc(*'DIVX'),30, size)\n",
    "    for i in range(len(img_array)):\n",
    "        vidoutObj.write(img_array[i])\n",
    "    vidoutObj.release()\n",
    "    # Release everything if job is finished\n",
    "    bg.release()\n",
    "    fg.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press q to exit\n",
      "Can't receive frame. Exiting ...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "  \n",
    "    # Calling the function \n",
    "    fgpath = \"input_data\\\\question3\\\\fg.mp4\"\n",
    "    bgpath = \"input_data\\\\question3\\\\bg.mp4\"\n",
    "    output_dir = \"output_data\\chroma_keying\"\n",
    "    chroma_keying(bgpath,fgpath,output_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 : Face Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Face_Detection():\n",
    "\n",
    "    # Load the cascade\n",
    "    face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    # To capture video from webcam. \n",
    "    capture = cv.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame\n",
    "        _, img = capture.read()\n",
    "        # Convert to grayscale\n",
    "        gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "        # Detect the faces\n",
    "        faces = face_cascade.detectMultiScale(gray, 2, 4)\n",
    "        # Draw the rectangle around each face\n",
    "        for (x, y, w, h) in faces:\n",
    "            cv.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        # Display\n",
    "        cv.imshow('img', img)\n",
    "        # Stop if escape key is pressed\n",
    "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    # Release the VideoCapture object\n",
    "    capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': \n",
    "  \n",
    "    # Calling the function \n",
    "    Face_Detection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
